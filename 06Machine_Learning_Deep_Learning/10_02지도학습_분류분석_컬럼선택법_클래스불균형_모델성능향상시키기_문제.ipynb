{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348d8c5f",
   "metadata": {},
   "source": [
    "# 은행 고객 예금 가입 예측: 고급 분석 실습 (불균형 처리 · 누수 점검 · 학생용 TODO ONLY)\n",
    "데이터: bank-additional-full.csv\n",
    "작성시각: 2025-10-29 07:45\n",
    "\n",
    "이 노트북은 실제 은행 텔레마케팅 캠페인 데이터를 바탕으로,\n",
    "EDA → 전처리 → 데이터 불균형 처리(SMOTE 등) → duration 누수 확인 → 모델 학습/평가 → 비즈니스 리포트\n",
    "엔드투엔드 파이프라인 전체를 직접 구현하는 실습입니다.\n",
    "\n",
    "중요:\n",
    "- 각 코드 셀에는 'TODO:'만 있고 실제 코드는 없습니다.\n",
    "- 모든 분석/시각화/학습/평가는 직접 작성해야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65256f",
   "metadata": {},
   "source": [
    "## 1. 문제 정의 / 비즈니스 맥락\n",
    "- 은행은 텔레마케팅(전화 캠페인)으로 정기예금 상품을 판매하려고 한다.\n",
    "- 타깃 변수 `y`: 'yes' = 실제로 가입했다, 'no' = 가입 안 했다.\n",
    "- 'yes' 비율은 매우 낮다 → 클래스 불균형(imbalanced data) 상황이다.\n",
    "- 콜센터 인력/시간은 비용이 크다.\n",
    "  → \"누구에게 우선 전화할 것인가?\"를 예측 모델로 결정하고 싶다.\n",
    "- 이 문제는 단순 정확도(accuracy)보다\n",
    "  - 가입 가능성이 있는 고객을 최대한 놓치지 않는 능력(recall),\n",
    "  - 헛콜을 줄이는 능력(precision),\n",
    "  - 전체 분류력(ROC-AUC)\n",
    "  같은 지표가 더 중요할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17765f",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드 & 기본 개요\n",
    "목표:\n",
    "- CSV 데이터를 읽어 DataFrame으로 준비한다.\n",
    "- 데이터 형태(shape), 컬럼명, 타입, 기본 통계 요약을 파악한다.\n",
    "\n",
    "필수 확인 포인트:\n",
    "- 어떤 컬럼이 숫자형인지, 문자열(범주형)인지\n",
    "- 타깃 변수 `y`의 값 분포\n",
    "- 각 특성(feature)의 스케일(범위)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8319c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. bank-additional-full.csv 파일을 ';' 구분자로 읽어서 df 라는 이름의 DataFrame으로 저장하세요.\n",
    "# 2. df.shape 와 df.head()를 출력해서 행/열 수와 데이터 샘플을 확인하세요.\n",
    "# 3. df.info()를 호출해서 컬럼별 데이터 타입과 결측치 여부를 확인하세요.\n",
    "# 4. df.describe(include='all').T 를 출력해서 기본 통계 요약(숫자형/범주형 모두)을 확인하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d836678",
   "metadata": {},
   "source": [
    "## 3. 데이터 품질 점검 (결측치 / 중복 / 특이값 / 클래스 비율)\n",
    "목표:\n",
    "- 결측치가 있는가?\n",
    "- 중복된 행이 있는가?\n",
    "- 타깃 y의 클래스 비율은 어느 정도로 불균형인가?\n",
    "- 특정 컬럼이 이상한 코드값(예: 999)을 쓰고 있는가?\n",
    "- duration(통화 길이)처럼 극단적으로 치우친 값이 있는가?\n",
    "\n",
    "힌트:\n",
    "- `pdays` 컬럼은 999라는 특이값을 많이 가지는데,\n",
    "  이건 '이전에 캠페인으로 연락한 적 없음'이라는 의미로 쓰인다.\n",
    "- `duration`은 실제 통화가 얼마나 길었는지(초). 이 값은 \"통화가 끝난 뒤\"에만 알 수 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5abbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. 각 컬럼별 결측치 개수를 계산하고 내림차순으로 출력하세요.\n",
    "#    (df.isna().sum().sort_values(ascending=False))\n",
    "#\n",
    "# 2. df.duplicated().sum() 으로 중복 행이 몇 개인지 출력하세요.\n",
    "#\n",
    "# 3. 타깃 y 의 분포를 value_counts(), value_counts(normalize=True)로 확인하세요.\n",
    "#    그리고 막대그래프로 시각화하세요 (y가 yes/no 중 어느 쪽이 얼마나 많은지).\n",
    "#\n",
    "# 4. pdays 컬럼의 상위 value_counts()를 출력해보고 999가 의미하는 바를 주석으로 적어보세요.\n",
    "#\n",
    "# 5. duration 컬럼에 대해 describe()를 출력하고,\n",
    "#    최소/최대/평균 등을 바탕으로 이상치(극단적 길이)가 존재하는지 메모하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100c7cc",
   "metadata": {},
   "source": [
    "## 4. EDA (탐색적 분석)\n",
    "이 단계에서는\n",
    "- 숫자형/범주형 컬럼을 자동으로 분리하고\n",
    "- 분포, 관계, 상관성을 시각적으로 점검한다.\n",
    "\n",
    "4.1 숫자형/범주형 컬럼 자동 분리  \n",
    "4.2 숫자형 분포(히스토그램)  \n",
    "4.3 범주형 분포(막대그래프) 및 y별 비교  \n",
    "4.4 y와 연속형 변수 관계(boxplot)  \n",
    "4.5 상관관계 히트맵(수치형 vs y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. get_numeric_columns(df), get_categorical_columns(df) 라는 함수를 직접 정의하세요.\n",
    "#    - 숫자형 컬럼 목록만 반환\n",
    "#    - 범주형(문자형 등) 컬럼 목록만 반환\n",
    "#\n",
    "# 2. numeric_cols, categorical_cols 변수에 그 결과를 담고 출력하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34645858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 숫자형 컬럼(numeric_cols)에 대한 히스토그램을 그리세요.\n",
    "# 힌트: df[numeric_cols].hist(figsize=(12,8), bins=20) 형태로 전체 분포를 한 번에 볼 수 있습니다.\n",
    "# 각 컬럼마다 값의 분포가 치우쳐 있는지(스큐), 극단값이 있는지 메모하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bccf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 범주형 컬럼(categorical_cols)의 값 분포를 막대그래프로 그리세요.\n",
    "# - 반복문으로 각 col마다 value_counts() 상위 순서대로 막대그래프(countplot 등)를 그리고\n",
    "#   x tick을 회전해서 보이게 하세요.\n",
    "#\n",
    "# 추가로 예시:\n",
    "# - 특정 범주형 변수(예: job)에 대해 hue='y' 로 countplot을 그려서\n",
    "#   어떤 직업군에서 'yes'가 상대적으로 더 많이 나오는지 확인하세요.\n",
    "#   (= 캠페인 타깃팅 힌트)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# boxplot을 사용해 y에 따라 age 분포가 어떻게 다른지 그리세요.\n",
    "# boxplot을 사용해 y에 따라 duration 분포가 어떻게 다른지도 그리세요.\n",
    "#\n",
    "# 관찰한 점을 마크다운 셀로 기록하세요:\n",
    "# 예) \"가입한 사람(yes)은 duration이 전반적으로 더 길다\" 같은 해석.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. df.copy()로 복사한 후 y를 0/1로 변환한 새 컬럼 (예: y_num) 을 만드세요.\n",
    "#    예: 'yes' -> 1, 'no' -> 0\n",
    "#\n",
    "# 2. numeric_cols + ['y_num'] 로 상관계수 행렬을 구하세요.\n",
    "#\n",
    "# 3. heatmap 으로 시각화하세요.\n",
    "#    어떤 수치형 변수가 y_num과 양(+)의 상관/음(-)의 상관을 가지는지 확인하고\n",
    "#    그 의미를 간단히 적어보세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb93e15",
   "metadata": {},
   "source": [
    "## 5. 전처리 / 파생변수 / 인코딩 / 데이터셋 분리 / 스케일링\n",
    "목표:\n",
    "- y를 0/1 숫자로 변환\n",
    "- 비즈니스 룰 기반 파생변수 만들기 (예: 이전 캠페인에서 연락한 적 없는지 여부)\n",
    "- duration은 실제 통화가 끝난 뒤에만 알 수 있으므로, 실제 배포 모델에서는 쓰지 않는 버전도 함께 준비\n",
    "- 범주형 변수를 더미변수로 변환 (pd.get_dummies)\n",
    "- 학습/평가용 train/test 분리 (층화 stratify 사용)\n",
    "- 숫자형 컬럼만 StandardScaler로 스케일링해서 로지스틱 회귀에 투입할 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. 타깃 y를 0/1로 변환한 Series를 만드세요. (예: {'no':0, 'yes':1} 매핑)\n",
    "#\n",
    "# 2. 특징행렬 X_full 을 df에서 y만 제거한 형태로 만들고 복사하세요.\n",
    "#\n",
    "# 3. 'pdays == 999' 여부를 나타내는 파생변수 no_prev_contact 를 X_full에 추가하세요.\n",
    "#    이건 '이전 캠페인에서 연락한 적 없음'이라는 비즈니스 신호입니다.\n",
    "#\n",
    "# 4. duration 은 통화가 끝나야만 알 수 있는 정보입니다.\n",
    "#    실제 캠페인 사전 추천 모델에는 넣을 수 없으므로,\n",
    "#    duration 을 뺀 버전 X_nodur 를 따로 만드세요.\n",
    "#\n",
    "# 5. 두 버전에 대해 pd.get_dummies(drop_first=True)로 범주형 원-핫 인코딩을 하세요.\n",
    "#    예: X_full_enc, X_nodur_enc\n",
    "#\n",
    "# 6. train_test_split을 사용해서 각 버전을 학습/테스트(예: 80/20)로 나누세요.\n",
    "#    stratify=y 를 꼭 사용하세요. (불균형 유지)\n",
    "#    예: Xf_train, Xf_test, yf_train, yf_test\n",
    "#        Xn_train, Xn_test, yn_train, yn_test\n",
    "#\n",
    "# 7. StandardScaler를 사용해 숫자형 컬럼만 스케일링한 학습/테스트 버전을 만드세요.\n",
    "#    - WITH duration 용 (Xf_train_scaled / Xf_test_scaled)\n",
    "#    - NO duration 용  (Xn_train_scaled / Xn_test_scaled)\n",
    "#\n",
    "# 8. 왜 duration 특징이 실제 배포 모델에 들어가면 안 되는지\n",
    "#    마크다운 셀로 설명하세요.\n",
    "#    키워드: \"데이터 누수(data leakage)\", \"미래 정보\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f275dc",
   "metadata": {},
   "source": [
    "## 6. 데이터 불균형 처리 (SMOTE / RandomOverSampler / RandomUnderSampler)\n",
    "목표:\n",
    "- 학습 데이터에서 'yes' 클래스(가입 고객)가 매우 적은 문제를 완화한다.\n",
    "- Over-sampling: 소수 클래스를 늘린다.\n",
    "  - RandomOverSampler: 단순 복제\n",
    "  - SMOTE: 인공적으로 합성 샘플 생성\n",
    "- Under-sampling: 다수 클래스를 줄인다.\n",
    "  - RandomUnderSampler\n",
    "- resampling 전과 후의 클래스 분포를 비교하고 시각화한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. 현재 학습 데이터(예: Xn_train / yn_train 처럼 duration 제거 버전의 train 세트)의\n",
    "#    타깃 클래스 분포를 bar 플롯으로 시각화하세요.\n",
    "#\n",
    "# 2. RandomOverSampler로 오버샘플링:\n",
    "#    - X_ros, y_ros 를 만들고\n",
    "#    - y_ros의 클래스 분포를 출력하세요.\n",
    "#\n",
    "# 3. SMOTE로 오버샘플링:\n",
    "#    - X_smote, y_smote 를 만들고\n",
    "#    - y_smote의 클래스 분포를 출력하세요.\n",
    "#\n",
    "# 4. RandomUnderSampler로 언더샘플링:\n",
    "#    - X_rus, y_rus 를 만들고\n",
    "#    - y_rus의 클래스 분포를 출력하세요.\n",
    "#\n",
    "# 5. 원본 vs SMOTE 결과 분포를 나란히 bar 차트로 그리고 비교하세요.\n",
    "#\n",
    "# 6. 마크다운 셀에 장단점을 적으세요:\n",
    "#    - Over-sampling의 장점/단점\n",
    "#    - Under-sampling의 장점/단점\n",
    "#    - 어떤 상황에서 어느 쪽이 더 적합하다고 생각하는지\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7b72b",
   "metadata": {},
   "source": [
    "## 7. 모델 학습 / 비교\n",
    "목표:<br>\n",
    "- 서로 다른 데이터/전처리 조건에서 모델을 학습시키고 비교한다.<br>\n",
    "\n",
    "아래 네 가지(최소)를 직접 학습/예측하세요:<br>\n",
    "\n",
    "1. Logistic Regression<br>\n",
    "   1-1. WITH duration (스케일된 Xf_train_scaled 사용, yf_train으로 학습)<br>\n",
    "   1-2. NO duration (스케일된 Xn_train_scaled 사용, yn_train으로 학습)<br>\n",
    "   1-3. NO duration + SMOTE (SMOTE로 만든 X_smote / y_smote 사용,<br>\n",
    "        이 데이터는 따로 스케일링해서 학습해야 함)<br>\n",
    "\n",
    "2. RandomForestClassifier<br>\n",
    "   2-1. NO duration (Xn_train / yn_train 사용)<br>\n",
    "   2-2. NO duration + SMOTE (X_smote / y_smote 사용)<br>\n",
    "        → 랜덤포레스트도 불균형 개선 효과를 비교해본다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# (1) 로지스틱 회귀 LogisticRegression\n",
    "#   a. WITH duration :\n",
    "#      - Xf_train_scaled / yf_train 으로 학습\n",
    "#      - Xf_test_scaled 로 예측 -> ypred_log_full, yprob_log_full\n",
    "#\n",
    "#   b. NO duration :\n",
    "#      - Xn_train_scaled / yn_train 으로 학습\n",
    "#      - Xn_test_scaled 로 예측 -> ypred_log_nodur, yprob_log_nodur\n",
    "#\n",
    "#   c. NO duration + SMOTE :\n",
    "#      - 먼저 X_smote / y_smote 에 대해 숫자형 컬럼만 다시 스케일링\n",
    "#        (train 기준으로 fit, test는 Xn_test 기준 transform)\n",
    "#      - 예측 -> ypred_log_smote, yprob_log_smote\n",
    "#\n",
    "# (2) 랜덤포레스트 RandomForestClassifier\n",
    "#   d. RF NO duration :\n",
    "#      - Xn_train / yn_train 으로 학습\n",
    "#      - Xn_test 로 예측 -> ypred_rf_nodur, yprob_rf_nodur\n",
    "#\n",
    "#   e. RF NO duration + SMOTE :\n",
    "#      - X_smote / y_smote 로 학습\n",
    "#      - Xn_test 로 예측 -> ypred_rf_smote, yprob_rf_smote\n",
    "#\n",
    "# 각 모델마다 class_weight='balanced' 또는 'balanced_subsample' 같은 옵션을 사용해서\n",
    "# 불균형 보정도 시도해보세요.\n",
    "#\n",
    "# 중요: duration 을 포함한 모델은 실제 배포 가능한 모델인가요? 아니면 누수(leakage) 때문에 금지인가요?\n",
    "#      마크다운 셀에 설명하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ab2f6",
   "metadata": {},
   "source": [
    "## 8. 평가 / 비교 (classification_report, ROC-AUC, ROC Curve)\n",
    "목표:\n",
    "- 각 모델의 성능을 서로 비교한다.\n",
    "- 단순 accuracy가 아니라, recall / precision / f1-score / ROC-AUC 같은 지표를 집중해서 본다.\n",
    "- ROC Curve를 한 그래프에 겹쳐서 시각화하고 차이를 해석한다.\n",
    "\n",
    "여기서는 로지스틱 회귀뿐 아니라 랜덤포레스트도\n",
    "SMOTE 전/후 버전을 비교해서 시각화해야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a08532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# 1. classification_report를 이용해 각 모델의 정밀도(precision), 재현율(recall),\n",
    "#    f1-score를 출력하세요.\n",
    "#\n",
    "#    예시로 비교해야 하는 모델들:\n",
    "#    - LogReg WITH duration\n",
    "#    - LogReg NO duration\n",
    "#    - LogReg NO duration + SMOTE\n",
    "#    - RF NO duration\n",
    "#    - RF NO duration + SMOTE\n",
    "#\n",
    "# 2. roc_auc_score 로 각 모델의 ROC-AUC를 계산하세요.\n",
    "#\n",
    "# 3. roc_curve 를 사용해\n",
    "#    (a) 로지스틱 3개 (WITH duration / NO duration / NO duration+SMOTE)\n",
    "#    (b) 랜덤포레스트 2개 (NO duration / NO duration+SMOTE)\n",
    "#    각각 ROC 곡선을 그리고, AUC 값을 범례 라벨에 넣으세요.\n",
    "#\n",
    "#    즉, ROC 그래프를 2장 그려도 됩니다:\n",
    "#    - 그래프1: 로지스틱 3종 비교\n",
    "#    - 그래프2: 랜덤포레스트 2종 비교\n",
    "#\n",
    "# 4. 어떤 모델이 \"현실 배포 가능한 모델\"인지, 그 이유를 마크다운 셀에 작성하세요.\n",
    "#    (duration이 있는 모델은 왜 배포 불가인가?)\n",
    "#\n",
    "# 5. SMOTE가 특히 어느 모델에서(로지스틱 vs 랜덤포레스트) 더 큰 이득을 줬는지,\n",
    "#    그 근거를 적으세요. (recall 향상? AUC 향상?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885d403",
   "metadata": {},
   "source": [
    "## 9. 리포트 질문 (마크다운 셀에 직접 서술)\n",
    "Q1. duration(통화 길이) 변수를 학습에 포함하면 왜 안 될까요?\n",
    "    - '데이터 누수(data leakage)'라는 표현을 포함해서 3줄 이상으로 설명하세요.\n",
    "\n",
    "Q2. SMOTE처럼 소수 클래스(가입 고객)를 증폭시키는 방식은 어떤 장점과 위험을 동시에 가지고 있나요?\n",
    "    - recall, precision 관점에서 설명해보세요. (3줄 이상)\n",
    "\n",
    "Q3. 실제 은행 마케팅 KPI(콜 인력 비용, 고객 피로도, 브랜드 이미지 등)를 생각했을 때\n",
    "    어떤 지표를 핵심 지표로 선택하겠습니까?\n",
    "    - recall(가입할 고객을 놓치지 않기) vs precision(헛콜 줄이기) vs F1 vs ROC-AUC\n",
    "    중 하나를 골라서 4줄 이상으로 설득력 있게 적어보세요.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
